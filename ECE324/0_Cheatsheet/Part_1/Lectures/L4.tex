\begin{definition}
    Learnable \textbf{(optimizable)} transformations of data.
    \begin{equation}
        x \overset{\text{Model}}{\mapsto} y
    \end{equation}
\end{definition}

\subsection{Challenges in NN Training}
\begin{notes}
    \begin{itemize}
        \item Non-convex loss landscapes
        \item Vanishing/exploding gradients
        \item Overfitting to training data
        \item Computational cost
    \end{itemize}
\end{notes}

\subsection{Neural Network Analogies}
\begin{notes}
    \begin{itemize}
        \item \textbf{Black box:} Internal workings are not interpretable, making it difficult to understand how decisions are made.
        \item \textbf{Glass box:} Structure and decision-making process are interpretable.
        \item \textbf{Cave:} Internal workings are not interpretable, but model can be understood with effort. 
    \end{itemize}
\end{notes}

\newpage

\subsection{Geometric Intuition}
\begin{summary}
    \begin{center}
        \begin{tabular}{ll}
            \toprule
            \textbf{Concept} & \textbf{Description} \\
            \midrule
            Decision surfaces & Different ways of cutting up space to make predictions. \\
            \multicolumn{2}{p{\linewidth}}{\begin{center}
                \customFigure[0.5]{../Images/L2_5.png}{}
                \vspace{-4em}
            \end{center}}\\
            \midrule
            Linear Transformation & Transform data from one vector space to another: $W \cdot x$ \\
            \multicolumn{2}{p{\linewidth}}{\begin{itemize}
                \item $W$: Linear transformation, $x$: Vector
            \end{itemize}}\\
            \midrule
            SVD of Linear Transformation & Factorizing matrices into geometrical transformations: $W = U \Sigma V^T$ \\
            \multicolumn{2}{p{\linewidth}}{\begin{itemize}
                \item $U,V$: Rotation or reflection, $\Sigma$: Scaling
            \end{itemize}}\\ 
            \midrule
            Affine Transformation & Transform data from one vector space to another: $W \cdot x + b$ \\
            \multicolumn{2}{p{\linewidth}}{\begin{itemize}
                \item $W$: Linear transformation, $x$: Vector, $b$: Bias vector
                \item Translate (b), Rotate (W-SVD), Reflect (W-SVD), Scale (W-SVD)
                \item Project up or down (dimensionality of $W \mathbf{x}$)
            \end{itemize}}\\
            \midrule
            Neural nets & Learn to warp space to make better predictions. \\
            \multicolumn{2}{p{\linewidth}}{\begin{center}
                \customFigure[0.5]{../Images/L2_6.png}{}
                \customFigure[0.5]{../Images/L2_7.png}{}
                \vspace{-4em}
            \end{center}}\\
        \end{tabular}
    \end{center}
\end{summary}
\newpage

\subsection{Data}
\begin{summary}
    \begin{center}
        \begin{tabular}{ll}
        \toprule
        \textbf{Techniques} & \textbf{Description} \\
        \midrule
        \textbf{Data Exploration} & Initial data inspection informs modeling choices. \\
        \multicolumn{2}{p{\linewidth}}{
        \begin{itemize}
            \item Think in terms of "x" and "y".
            \item Summary statistics
            \item Identifying data imbalances
            \item \textbf{Libraries:} Pandas, Matplotlib, Seaborn
        \end{itemize}} \\
        \midrule
        \textbf{Data Splitting} & Proper data partitioning prevents overly optimistic performance estimates. \\
        \multicolumn{2}{p{\linewidth}}{
        \begin{center}
            \customFigure[0.5]{../Images/L4_0.png}{}
            \vspace{-4em}
        \end{center}} \\
        \midrule
        \textbf{Cross-Validation} & Assess model performance across multiple data partitions. \\
        \multicolumn{2}{p{\linewidth}}{
        \begin{itemize}
            \item Provides more reliable performance estimates. 
            \customFigure[0.5]{../Images/L4_1.png}{}
        \end{itemize}} \\
        \bottomrule
        \end{tabular}
    \end{center}
\end{summary}
\newpage

\begin{summary}
    \begin{center}
        \begin{tabular}{ll}
        \toprule
        \textbf{Techniques} & \textbf{Description} \\
        \midrule
        \textbf{Stratified Splitting} & Ensure each data split reflects the original class distribution. \\
        \multicolumn{2}{p{\linewidth}}{
        \begin{itemize}
            \item Maintains class proportions. 
            \begin{itemize}
                \item Stratification will balance one classification label.  
            \end{itemize}
            \customFigure[0.5]{../Images/L4_2.png}{}
        \end{itemize}} \\
        \midrule
        \textbf{Adversarial Splits} & Evaluate model perf. under challenging, out-of-distribution scenarios for robustness. \\
        \multicolumn{2}{p{\linewidth}}{
        \begin{itemize}
            \item Leave out: Clusters, Labels, Temporal Data
            \customFigure[0.5]{../Images/L4_3.png}{}
        \end{itemize}} \\
        \bottomrule
        \end{tabular}
    \end{center}
\end{summary}
\newpage

\begin{summary}
    \begin{center}
        \begin{tabular}{ll}
        \toprule
        \textbf{Techniques} & \textbf{Description} \\
        \midrule
        \textbf{Data Augmentation} & Create new training ex. by applying trans. to existing data for $\uparrow$ data variability. \\
        \multicolumn{2}{p{\linewidth}}{
        \begin{itemize}
            \item Transformations should be relevant to the data.
            \item Increase data size.
            \item Bake in "biases"/"priors" into your model.
            \customFigure[0.5]{../Images/L4_4.png}{}
        \end{itemize}} \\
        \midrule
        \textbf{Image Augmentation} & Apply transformations like rotations, flips, and crops to images. \\
        \multicolumn{2}{p{\linewidth}}{
        \begin{center}
            \customFigure[0.5]{../Images/L4_5.png}{}
            \vspace{-4em}
        \end{center}} \\
        \bottomrule
        \end{tabular}
    \end{center}
\end{summary}
\newpage

\subsection{Evaluation Metrics Quantify Performance}
\begin{summary}
    \begin{center}
        \begin{tabular}{ll}
        \toprule
        \textbf{Metrics} & \textbf{Description} \\
        \midrule
        \textbf{Classification Metrics} &  \\
        \midrule 
        Accuracy & $\frac{\text{Correct Predictions}}{\text{Total Predictions}}$ \\
        \multicolumn{2}{p{\linewidth}}{
        \begin{itemize}
            \item \textbf{When to Use?} (1) classes are balanced and (2) false +/false - have similar importance.
        \end{itemize}} \\
        \midrule
        Precision & $\frac{\text{True Positives}}{\text{True Positives} + \text{False Positives}}$ \\
        \multicolumn{2}{p{\linewidth}}{
        \begin{itemize}
            \item \textbf{When to Use?} (1) false + are costly (e.g. nuclear war, since saying there is a nuclear war when there's not is bad) and (2) you want to minimize false +.
        \end{itemize}} \\
        \midrule 
        Recall & $\frac{\text{True Positives}}{\text{True Positives} + \text{False Negatives}}$ \\
        \multicolumn{2}{p{\linewidth}}{
        \begin{itemize}
            \item \textbf{When to Use?} (1) false - are costly (e.g. cancer detection, since missing cancer when there's cancer is bad) and (2) you want to minimize false -.
        \end{itemize}} \\
        \midrule 
        F1-Score & $2 \times \frac{\text{Precision} \times \text{Recall}}{\text{Precision} + \text{Recall}}$ \\
        \multicolumn{2}{p{\linewidth}}{
        \begin{itemize}
            \item \textbf{When to Use?} (1) you want to balance precision and recall.
        \end{itemize}} \\
        \midrule 
        AUROC & Area under the ROC curve. \\
        \multicolumn{2}{p{\linewidth}}{
        \begin{itemize}
            \item \textbf{How?} Assesses model perf. across all class. thresholds by plotting true + rate against false + rate.
            \item \textbf{Char.} Monotonic, ranking-based, $1.0$ is perfect, $0.5$ is random.
            \customFigure[0.3]{../Images/L4_8.png}{}
            \vspace{-1em}
        \end{itemize}} \\
        \midrule 
        AUPRC & Area under the Precision-Recall curve. \\
        \multicolumn{2}{p{\linewidth}}{
            \begin{itemize}
                \item \textbf{How?} Assesses model performance across all classification thresholds by plotting precision against recall.
                \item \textbf{When to Use?} (1) classes are imbalanced as it focuses on trade-offs between precision and recall.
        \end{itemize}} \\
        \midrule
        Average Precision (AP) & $\sum_n \text{Precision}(n) \times \text{Recall}(n)$ \\
        \multicolumn{2}{p{\linewidth}}{
            \begin{itemize}
                \item \textbf{What?} Measures how well a model ranks positive examples above negative examples.
                \item \textbf{When to Use?} (1) summarize precision-recall curve, making it suitable for ranking tasks.
            \end{itemize}} \\
        \midrule
        \end{tabular}
    \end{center}
\end{summary}
\newpage

\begin{summary}
    \begin{center}
        \begin{tabular}{ll}
        \toprule
        \textbf{Metrics} & \textbf{Description} \\
        \midrule
        Mean Average Precision (mAP) & $\frac{1}{N} \sum_{n=1}^{N} \text{AP}(n)$ \\
        \multicolumn{2}{p{\linewidth}}{
        \begin{itemize}
                \item \textbf{When to Use?} (1) multi-class or object detection tasks to compute the average AP across classes.
        \end{itemize}} \\
        \midrule
        Intersection over Union (IoU) & $\frac{\text{Area of Overlap}}{\text{Area of Union}}$ \\
        \multicolumn{2}{p{\linewidth}}{
            \begin{itemize}
                \item \textbf{When to Use?} (1) object detection tasks to evaluate the overlap between predicted and ground truth bounding boxes.
            \end{itemize}} \\
        \toprule
        \textbf{Regression Metrics} & $R^2$, MAE, Pearson $r$, RMSE, MSE, MAPE \\ 
        \midrule 
        $R^2$ and Pearson's $r$ & Quantify linear associations. \\
        \multicolumn{2}{p{\linewidth}}{
        \begin{itemize}
            \item \( R^2 \): Can be infinitely worse in some cases, context-dependent.
            \begin{itemize}
                \item \( R^2 = 0 \): Represents the mean of the data.
                \item \( R^2 = 1 \): Indicates a perfect fit.
            \end{itemize}
            \customFigure[0.3]{../Images/L4_9.png}{}
        \end{itemize}} \\
        \midrule
        \textbf{Ranking Correlation Metrics} & Kendall Tau, Spearman measure monotonic relationships \\
        \midrule 
        Spearman & Similar to Pearson correlation but applied to ranks. \\
        \multicolumn{2}{p{\linewidth}}{
        \begin{itemize}
            \item Magnitude does not matter.
            \item Applicable for regression or classification tasks.
        \end{itemize}} \\
        \midrule
        Kendall & Pair-based approach, determines if the order is correct or not. \\
        \multicolumn{2}{p{\linewidth}}{
        \begin{itemize}
            \item Magnitude does not matter.
            \item Applicable for regression or classification tasks.
        \end{itemize}} \\
        \midrule
        \textbf{Multitask Metrics} & Mean of metrics, holistic metric \\
        \bottomrule
        \end{tabular}
    \end{center}
\end{summary}
\newpage

\begin{summary}
    \begin{center}
        \begin{tabular}{ll}
        \toprule
        \textbf{Concepts} & \textbf{Description} \\
        \midrule
        \textbf{Adjusting Decision Thresholds} & Modifying the threshold impacts precision and recall. \\
        \multicolumn{2}{p{\linewidth}}{
        \begin{itemize}
            \item How to interpret your probabiltiies is a modelling decision.
            \customFigure[0.4]{../Images/L4_6.png}{}
        \end{itemize}} \\
        \midrule
        \textbf{Calibrating Predicted Probabilities} & Predicted probabilities may not reflect true likelihood. \\
        \multicolumn{2}{p{\linewidth}}{
        \begin{center}
            \customFigure[0.4]{../Images/L4_7.png}{}
            \vspace{-4em}
        \end{center}} \\
        \midrule
        \textbf{Quantifying Metric Uncertainty} & Confidence intervals provide a range of plausible values. \\
        \multicolumn{2}{p{\linewidth}}{
        \begin{center}
            \customFigure[0.5]{../Images/L4_10.png}{}
            \vspace{-4em}
        \end{center}} \\
        \bottomrule
        \end{tabular}
    \end{center}
\end{summary}
\newpage

\begin{summary}
    \begin{center}
        \begin{tabular}{ll}
        \toprule
        \textbf{Concepts} & \textbf{Description} \\
        \midrule
        \textbf{Bootstrapping for Robust Estimation} & Resampling with replacement estimates metric variability. \\
        \multicolumn{2}{p{\linewidth}}{
        \begin{itemize}
            \item \textbf{Resample:} Create many datasets by randomly picking data points with replacement from your original data.
            \item \textbf{Calculate:} Compute your metric of interest on each of these resampled datasets.
            \item \textbf{Estimate:} Use the distribution of these calculated metrics to estimate the uncertainty (e.g., confidence interval) of your original metric.
        \end{itemize}} \\
        \bottomrule
        \end{tabular}
    \end{center}
\end{summary}
\newpage

\subsection{Optimization / Training}
\begin{summary}
    \begin{center}
        \begin{tabular}{ll}
        \toprule
        \textbf{Tools} & \textbf{Description} \\
        \midrule
        \textbf{Gradient Descent} & Update weights and biases \\
        \multicolumn{2}{p{\linewidth}}{
        \begin{itemize}
            \item \textbf{Heuristic:} Use Adam and finetune learning rate.
            \item \textbf{Momentum:} Accelerate convergence by using prior update info. 
        \end{itemize}} \\
        \midrule
        \textbf{Batch Size} & \# of samples per gradient update affects learning. \\
        \multicolumn{2}{p{\linewidth}}{
        \begin{itemize}
            \item \textbf{Trade-Off:} Smaller batch size $\rightarrow$ gradient variability, larger batch size $\rightarrow$ computationally efficient.
            \begin{itemize}
                \item Batch size governs the training speed and shouldn't be used to directly tune the validation set performance. 
            \end{itemize}
            \item \textbf{Heuristic:} Ideal batch size will be the largest batch size supported by the available hardware.
        \end{itemize}} \\
        \midrule
        \textbf{Learning Rate} & Try a range of values. \\
        \multicolumn{2}{p{\linewidth}}{
        \begin{itemize}
            \item \textbf{Trade-Off:} High learning rate $\rightarrow$ faster training, possibility of not stabilizing (offshoot the minima), low learning rate $\rightarrow$ slow.  
            \item \textbf{Heuristics:} Typically in the $1e^{-1}$ to $1e^{-6}$ range, use \texttt{log10} scale, use low for fine-tuning, $1e^{-5} - 1e^{-6}$
            \item \textbf{Note:} Dataset/model/batch dependent
        \end{itemize}} \\
        \midrule
        \textbf{Learning Rate Decay} & Dynamically adjust the learning rate during training to reduce oscillations \\ 
        \multicolumn{2}{p{\linewidth}}{
        \begin{itemize}
            \item Learning rate decay helps fine-tune the model in later stages of training, preventing overshooting the optimal parameters.
            \customFigure[0.3]{../Images/L4_11.png}{}
            \item \textbf{Plateau:} Learning rate decays only after hitting a plateau for a certain number of epochs.
            \customFigure[0.3]{../Images/L4_12.png}{}
        \end{itemize}} \\
        \bottomrule
        \end{tabular}
    \end{center}
\end{summary}
\newpage

\begin{summary}
    \begin{center}
        \begin{tabular}{ll}
        \toprule
        \textbf{Tools} & \textbf{Description} \\
        \midrule
        \textbf{Gradient Clipping} &  Prevents exploding gradients by limiting mag. of grad. during training. \\
        &  $g \leftarrow 
            \begin{cases} 
            \lambda \frac{g}{\|g\|} & \text{if } \|g\| > \lambda \\
            g & \text{otherwise}
            \end{cases}$ \\
        \multicolumn{2}{p{\linewidth}}{
        \begin{itemize}
            \item Typical values: 5 or 1.
            \customFigure[0.3]{../Images/L4_13.png}{}
        \end{itemize}} \\
        \midrule
        \textbf{Early Stopping} & Prevents overfitting by monitoring val. perform. \& stop training when it detior.\\
        \multicolumn{2}{p{\linewidth}}{
        \begin{itemize}
            \item Stop after negligible improvements.
            \item Save model and restore.
            \item Patience (how much to wait before stopping).
            \customFigure[0.3]{../Images/L4_14.png}{}
        \end{itemize}} \\
        \midrule
        \textbf{Loss Function Weighting} & Assign different weights to different classes during loss calculation. \\
        & $L_w(y, \hat{y}) = \frac{1}{\sum w_n} \sum_{n} w_n L(y_n, \hat{y}_n)$ \\
        \multicolumn{2}{p{\linewidth}}{
        \begin{itemize}
            \item Weights can be inverse class frequency.
        \end{itemize}} \\
        \midrule
        \textbf{Activation fn} & Hyperparameter that introduces non-linearity (gating-like). \\
        \multicolumn{2}{p{\linewidth}}{
        \begin{itemize}
            \item \textbf{Heuristic:} Use ReLU, GeLU. Don't spend too mcuh time on it. 
            \item \textbf{ReLU:} $f(x)= \max(0,x)$ Rectified linear unit, which has a geometric effect of "gating" the input.
                \customFigure[0.2]{../Images/L2_8.png}{}
                \vspace{-1em}
            \item \textbf{Tension:} smoothness/compute/complexity.
        \end{itemize}} \\
        \bottomrule
        \end{tabular}
    \end{center}
\end{summary}
\newpage

\begin{summary}
    \begin{center}
        \begin{tabular}{ll}
        \toprule
        \textbf{Tools} & \textbf{Description} \\
        \midrule
        \textbf{Masking} & Omit data when missing or NA by multiplying loss function by a binary valued mask. \\
            & $- \frac{1}{\sum \text{mask}} \sum_n \text{mask}_n \cdot (y_n - \hat{y}_n)^2$ \\
            \multicolumn{2}{p{\linewidth}}{
                \begin{itemize}
                    \item Good for NaN, $-\infty$, high value outliers.
                    \customFigure[0.3]{../Images/L3_5.png}{}
                    \vspace{-1em}
                \end{itemize}
            } \\
        \midrule
        \textbf{Focal Loss} & Focuses on hard examples by down-weighting the contribution of easy examples to the loss. \\
        & $FL(p_t, \gamma) = -(1 - p_t)^\gamma \log(p_t)$ \; Adds factors to cross-entropy loss fn \\
        \multicolumn{2}{p{\linewidth}}{
        \begin{center}
            \customFigure[0.5]{../Images/L4_15.png}{}
            \vspace{-4em}
        \end{center}} \\
        \bottomrule
        \end{tabular}
    \end{center}
\end{summary}
\newpage

\subsection{Regularization \& Modelling}
\begin{summary}
    \begin{center}
        \begin{tabular}{ll}
        \toprule
        \textbf{Tools} & \textbf{Description} \\
        \midrule
        \textbf{Normalization Standardizes Feature Distributions} & Scale input features to be $\mathcal{N}(0,1)$ \\
        \multicolumn{2}{p{\linewidth}}{
        \begin{itemize}
            \item Stability, Speed, Prevents large scale features from dominating.
            \customFigure[0.3]{../Images/L4_16.png}{}
        \end{itemize}} \\
        \midrule
        \textbf{Batch and Layer Normalization} & Normalize the activations across batch or features. \\
        \multicolumn{2}{p{\linewidth}}{
        \begin{center}
            \customFigure[0.3]{../Images/L4_17.png}{}
            \vspace{-4em}
        \end{center}} \\
        \midrule
        \textbf{Residual Connections Facilitate Deeper Networks} & Add the input of a layer to its output. \\
        \multicolumn{2}{p{\linewidth}}{
        \begin{center}
            \customFigure[0.3]{../Images/L4_18.png}{}
            \vspace{-4em}
        \end{center}} \\
        \bottomrule
        \end{tabular}
    \end{center}
\end{summary}
\newpage

\begin{summary}
    \begin{center}
        \begin{tabular}{ll}
        \toprule
        \textbf{Tools} & \textbf{Description} \\
        \midrule
        \textbf{Dropout} & Randomly setting activations elements to zero \\
        \multicolumn{2}{p{\linewidth}}{
        \begin{itemize}
            \item Reduce overfitting, create an ensemble of subnetworks implicitly.
            \customFigure[0.3]{../Images/L4_19.png}{}
        \end{itemize}} \\
        \midrule
        \textbf{Ensemble} & Combine multiple models to $\uparrow$ predictive performance \\
        & by aggregating predictions from diverse models. \\
        & $\hat{y} = \frac{1}{n} \sum_n^{\text{models}} f_n(x)$ \\
        \multicolumn{2}{p{\linewidth}}{
        \begin{itemize}
            \item Always will give an equal or better model w.r.t. predictive performance.
        \end{itemize}} \\
        \midrule
        \textbf{Random Init. Ensembles} & Diverse initial states improves ensemble diversity. \\
        & $\hat{y} = \frac{1}{n} \sum_n^{\text{models}} f_n(x;\theta_n)$ \\
        \multicolumn{2}{p{\linewidth}}{
        \begin{itemize}
            \item Same model, different random seeds.
        \end{itemize}} \\
        \midrule
        \textbf{Hyperparameter Ensembles} & Hyperparameter explorations give you more diverse ensembles. \\
        & $\hat{y} = \frac{1}{n} \sum_{n}^{\text{models}} f_n(x; \theta_n)$ \\
        \multicolumn{2}{p{\linewidth}}{
        \begin{itemize}
            \item $f_n \sim \text{comes from top-k models from a hyperparameter optimization, same model class}$
            \customFigure[0.3]{../Images/L4_20.png}{}
        \end{itemize}} \\
        \bottomrule
        \end{tabular}
    \end{center}
\end{summary}
\newpage

\begin{summary}
    \begin{center}
        \begin{tabular}{ll}
        \toprule
        \textbf{Tools} & \textbf{Description} \\
        \midrule
        \textbf{Uncertainty Quantification} & Variability in prediction by representing range of likely outcomes \\
        & rather than relying solely on a single point prediction. \\ 
        \multicolumn{2}{p{\linewidth}}{
        \begin{itemize}
            \item Uncertainty $~\text{std}(f_1\ldots f_n)$
            \customFigure[0.5]{../Images/L4_21.png}{}
        \end{itemize}} \\
        \midrule
        \textbf{Not All Uncertainty is the Same} & Some models offer more reliable uncertainty estimates. \\
        \multicolumn{2}{p{\linewidth}}{
        \begin{center}
            \customFigure[0.5]{../Images/L4_22.png}{}
            \vspace{-4em}
        \end{center}} \\
        \midrule
        \textbf{L1 Regularization} & Encourages sparsity by adding sum of $|\text{weights}|$ to the loss fn:  \\
        & $L(\theta) + \lambda \sum_i |\theta_i|$ \\
        \multicolumn{2}{p{\linewidth}}{
        \begin{itemize}
            \item Encouraging sparse weights
            \item Feature selection
        \end{itemize}} \\
        \midrule
        \textbf{L2 Regularization} & Penalizes large weights by adding sum of $\text{weights}^2$ to the loss fn:  \\
        & $L(\theta) + \lambda \sum_i \theta_i^2$ \\
        \multicolumn{2}{p{\linewidth}}{
        \begin{itemize}
            \item Weight decay
            \item Preventing overfitting
        \end{itemize}} \\
        \bottomrule
        \end{tabular}
    \end{center}
\end{summary}
\newpage

\subsection{Experiments}
\begin{summary}
    \begin{center}
        \begin{tabular}{ll}
        \toprule
        \textbf{Tools} & \textbf{Description} \\
        \midrule
        \textbf{Logging Metrics During Training} & Track relevant metrics to monitor progress and diagnose issues. \\
        \multicolumn{2}{p{\linewidth}}{
        \begin{center}
            \customFigure[0.5]{../Images/L4_23.png}{}
            \vspace{-4em}
        \end{center}} \\
        \midrule
        \textbf{Setting Up Baselines (Ref. Point)} & Establish a simple models to compare against. \\
        \multicolumn{2}{p{\linewidth}}{
        \begin{itemize}
            \item GLM model, Random forest, XGBoost, NGBoost (if you want uncertainty), SKlearn-like models
        \end{itemize}} \\
        \midrule
        \textbf{Seed Setting} & Set random seeds for reproducibility of results. \\
        \multicolumn{2}{p{\linewidth}}{
        \begin{center}
            \customFigure[0.5]{../Images/L4_26.png}{}
            \vspace{-4em}
        \end{center}} \\
        \bottomrule
        \end{tabular}
    \end{center}
\end{summary}
\newpage

\begin{summary}
    \begin{center}
        \begin{tabular}{ll}
        \toprule
        \textbf{Tools} & \textbf{Description} \\
        \midrule
        \textbf{Ablation Studies} & Evaluate systematically one axis. \\
        & Assess impact by controlled single-parameter changes. \\
        \multicolumn{2}{p{\linewidth}}{
        \begin{center}
            \customFigure[0.5]{../Images/L4_24.png}{}
            \vspace{-4em}
        \end{center}} \\
        \midrule
        \textbf{Context Matters:} & No Free Lunch Theorem \\
        & Best tricks depend on the specific task and dataset. \\
        \midrule
        \textbf{Storytelling Matters} & How you report number and values will change how ppl. think about it.  \\
        % \midrule
        % \textbf{MLP Hyperparameter Space} \\
        % \multicolumn{1}{p{\linewidth}}{
        % \begin{itemize}
        %     \item Better to simplify modelling choices
        %     \customFigure[0.3]{../Images/L4_27.png}{}
        % \end{itemize}} \\
        \bottomrule
        \end{tabular}
    \end{center}
\end{summary}