\begin{summary}
    In a \textbf{Multi-Agent problem}, we assume that:
    \begin{itemize}
        \item Set of states for environment is $\mathcal{S}$
        \item $P$ agents within environment. 
        \item For each state $s \in \mathcal{S}$: 
        \begin{itemize}
            \item possible actions for agent $i$ is $\mathcal{A}_i(s)$
            \item set of action profiles is $\mathcal{A}(s) = \prod_{i=1}^P \mathcal{A}_i(s)$
        \end{itemize}
        \item possible state-action pairs are $\mathcal{T} = \{(s,a) \text{ s.t. } s \in \mathcal{S}, a \in \mathcal{A}(s)\}$
        \item environment in some origin state, $s_0$ 
        \item environment destroyed after $N$ transitions 
        \item agent $j$ wants to find policy $\pi_j (a_j \mid s)$ so that $\mathbb{E}[r_j(p)]$ is maximized
        \item agents act independently given the environment's state: $\pi (a \mid s) = \prod_{j\in [P]} \pi_j (a_j \mid s)$
    \end{itemize}

    \begin{center}
        \begin{tabular}{ll}
            \toprule
            \textbf{Name} & \textbf{Function:} \\
            \midrule
            State transition given state-action pair defined by $\text{tr}: \mathcal{T} \to \mathcal{S}$ & $\text{tr}(s,a) = \text{state transition from $s$ under $a$}$ \\ 
            \midrule
            Reward to each agent, $i$ defined by $r_i$: $\mathcal{Q} \times \mathcal{S} \rightarrow \mathbb{R}_+$ & $r_i(s,a,\text{tr}(s,a)) = \text{rwd to agent $i$ for $(s,a,tr(s,a))$}$ \\
            \midrule
            State evolution of environment after $N$ transitions & $p = \langle (s_0,a^{(1)},s_{1}),\ldots,(s_{N-1},a^{(N)},s_{N})\rangle$ \\ 
            \multicolumn{2}{p{\linewidth}}{
            \begin{itemize}
                \item Given sequence of actions: $p.a = \langle a^{(1)},\ldots,a^{(n)}\rangle$
                \item $s_N = \tau (s_{n-1},a^{(n)})$
            \end{itemize}} \\
            \midrule
            reward to agent $i$ & $r_i(p) = \sum_{n=1}^N r_i (s_{n-1},a^{(n)}, s_n)$ \\
            \midrule
            expected-reward (value) of playing $a$ from $s$ for agent $j$ & $q_j (s,a) = r_j(s,a,\tau(s,a)) +$ \\
            & $\sum_{a' \in \mathcal{A}(\tau(s,a))} \pi(a' \mid \tau(s,a)) q_j(\tau(s,a),a')$ \\
            \multicolumn{2}{p{\linewidth}}{
                \begin{itemize}
                    \item $\mathcal{A}(s) = \emptyset$ if $s \in \mathcal{G}$
                \end{itemize}} \\
            \bottomrule            
        \end{tabular}
    \end{center}
\end{summary}

\subsection{Action Equilibria}

\subsubsection{Finding Action Equilibria}

\subsection{Strategy Equilibria}

\subsubsection{Finding Strategy Equilibria}

\subsubsection{Existence of Stategy Equilibria}

\subsubsection{Convergence of Stategy Equilibria}

\subsection{Examples}
\subsubsection{Finding Action Equilibria}

\subsubsection{Optimal Action Profiles}
\newpage
\begin{example}
    \begin{enumerate}
        \item \textbf{Given/Problem:} Find all equilibria of the following one-shot game or state that none exist.
        \vspace{1em}
            \begin{center}
            \begin{tabular}{ccc}
            \toprule
            & \textbf{B1 (y)} & \textbf{B2 (1-y)} \\
            \midrule
            \textbf{A1 (x)} & (5, 3) & (1, 0) \\
            \textbf{A2 (1-x)} & (0, 1) & (2, 4) \\
            \bottomrule
            \end{tabular}
            \end{center}
        \vspace{1em}
        \begin{itemize}
            \item (\#,\#) is the payoff to P1 and P2 respectively for a given action profile.
        \end{itemize}
        \item \textbf{Solution:}
        \begin{enumerate}
            \item \textbf{Define Probabilities:}
            \begin{itemize}
                \item Let $y$ be the probability that B1 plays action B1 so $1-y$ is the probability that B1 plays action B2.
                \item Let $x$ be the probability that A1 plays action A1 so $1-x$ is the probability that A1 plays action A2.
            \end{itemize}
            \item \textbf{Expected Rewards:} 
            \begin{itemize}
                \item P1: 
                \begin{align*}
                    E[x] = 5xy + 1x(1-y) + 0(1-x)y + 2(1-x)(1-y) &= 5xy + x - xy + 2 - 2x - 2y + 2xy \\
                    &= 5xy - xy + 2xy + x - 2x - 2y + 2 \\
                    &= 6xy - x - 2y + 2 \quad \text{simplify} \\
                    &= \underbrace{(6y - 1)}_{c}x + 2 - 2y \quad \text{linear in $x$} 
                \end{align*}
                \item P2:
                \begin{align*}
                    E[y] = 3xy + 0x(1-y) + 1(1-x)y + 4(1-x)(1-y) &= 3xy + 0 + y - xy + 4 - 4x - 4y + 4xy \\
                    &= 3xy - xy + 4xy + y - 4x - 4y + 4 \\
                    &= 6xy - 4x - 3y + 4 \quad \text{simplify} \\
                    &= \underbrace{(6x - 3)}_{c}y + 4 - 4x \quad \text{linear in $y$}
                \end{align*}
                \item \textbf{Note:} $E[x]$ is linear in $x$ and $E[y]$ is linear in $y$.
            \end{itemize}
            \item \textbf{Constrained Argmax Expected Rewards w.r.t $x \in [0,1]$ (since P1):} If it was cost, then minimize. Also don't care about constant term in $y$ since we are derivating w.r.t $x$.
            \begin{itemize}
                \item P1: 
                \begin{equation*}
                    x = \begin{cases}
                        1 & \text{if } y > \frac{1}{6} \text{ i.e. } c > 0 \text{ since positive want maximum positive}\\
                        & \\
                        [0,1] & \text{if } y=\frac{1}{6} \text{ i.e. }c = 0 \text{ doesn't matter since 0} \\
                        & \\
                        0 & \text{if } y < \frac{1}{6} \text{ i.e. } c < 0 \text{ since negative want maximum negative}
                    \end{cases}
                \end{equation*}
                \item P2:
                \begin{equation*}
                    y = \begin{cases}
                        1 & \text{if } x > \frac{3}{6} \text{ i.e. } c > 0 \text{ since positive want maximum positive}\\
                        & \\
                        [0,1] & \text{if } x=\frac{3}{6} \text{ i.e. }c = 0 \text{ doesn't matter since 0} \\
                        & \\
                        0 & \text{if } x < \frac{3}{6} \text{ i.e. } c < 0 \text{ since negative want maximum negative}
                    \end{cases}
                \end{equation*}
            \end{itemize}
            \item \textbf{Finding all equilibrium:} Lines on the graph represents where your reward is maximized. 
            \customFigure[0.5]{../Images/L11_9.png}{}
            \begin{itemize}
                \item \textbf{Case 1:} $x=0$ and $y=0$
                \begin{itemize}
                    \item $P(\text{P1 chooses A1}) = 0$ 
                    \item $P(\text{P1 chooses A2}) = 1$
                    \item $P(\text{P2 chooses B1}) = 0$
                    \item $P(\text{P2 chooses B2}) = 1$
                \end{itemize}
                \item \textbf{Case 2:} $x=1/2$ and $y=1/6$
                \begin{itemize}
                    \item $P(\text{P1 chooses A1}) = 1/2$
                    \item $P(\text{P1 chooses A2}) = 1/2$
                    \item $P(\text{P2 chooses B1}) = 1/6$
                    \item $P(\text{P2 chooses B2}) = 5/6$
                \end{itemize}
                \item \textbf{Case 3:} $x=1$ and $y=1$
                \begin{itemize}
                    \item $P(\text{P1 chooses A1}) = 1$
                    \item $P(\text{P1 chooses A2}) = 0$
                    \item $P(\text{P2 chooses B1}) = 1$
                    \item $P(\text{P2 chooses B2}) = 0$
                \end{itemize}
            \end{itemize}
            \item \textbf{Unstable Equilibrium:} P1 moves left and right b/c $x$ is associated with $x$-axis. P2 moves up and down b/c $y$ is associated with $y$-axis.
            \customFigure[0.5]{../Images/L11_10.png}{}
            \begin{itemize}
                \item Stability means that in a radius disc around the equilibrium, if you move a little bit, you will still be in the equilibrium (have to check all relevant quadrants)
                \begin{itemize}
                    \item If one quadrant is unstable, then don't need to check the other quadrants as the equilibrium point is unstable. 
                    \item Simulatenous (both players move at the same time) and sequential (one player moves first and the other player moves second) 
                \end{itemize}
                \item \textbf{Case 1:} $x=0$ and $y=0$ is stable
                \begin{itemize}
                    \item Q1: Always converges to $(0,0)$ since P1 moves left to red and P2 moves down to turquoise.
                \end{itemize}
                \item \textbf{Case 2:} $x=1/2$ and $y=1/6$ is unstable
                \begin{itemize}
                    \item Q1 (Top Left): P1 moves right to red and P2 moves up to turquoise $\implies (1,1)$
                    \item Q2 (Top Right): P1 moves right to red and P2 moves up to turquoise $\implies (1,1)$
                    \item Q3 (Bottom Left): P1 moves left to red and P2 moves down to turquoise $\implies (0,0)$
                    \item Q4 (Bottom Right): P1 moves left to red and P2 moves down to turquoise $\implies (0,0)$
                \end{itemize}
                \item \textbf{Case 3:} $x=1$ and $y=1$ is stable
                \begin{itemize}
                    \item Q1: Always converges to $(1,1)$ since P1 moves left to red and P2 moves down to turquoise.
                \end{itemize}
            \end{itemize}
        \end{enumerate}
    \end{enumerate}

\end{example}

